import type {
  FluidRegionState,
  InformationalFluidSnapshot,
} from "./L23_informational_fluid";

export interface LuckVector {
  // –í–µ–∫—Ç–æ—Ä –∏–∑ L21: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –∫—É–¥–∞ "—Ö–æ—á–µ—Ç" —Å–∏—Å—Ç–µ–º–∞
  focusTags: string[]; // —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–µ–π—á–∞—Å –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ
  riskAppetite: number; // 0..1 (0 - –∏–∑–±–µ–≥–∞—Ç—å —Ä–∏—Å–∫–∞, 1 - –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)
  changeDrive: number; // 0..1 (0 - —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å—Ç–∞—Ç—É—Å-–∫–≤–æ, 1 - –º–µ–Ω—è—Ç—å)
}

export interface TrajectoryStep {
  description: string;
  expectedDurationMs?: number;
  involvedRegions?: string[]; // –∫–∞–∫–∏–µ —Ä–µ–≥–∏–æ–Ω—ã L23 –∑–∞—Ç—Ä–æ–Ω–µ—Ç
  tags?: string[]; // —Å–º—ã—Å–ª–æ–≤—ã–µ —Ç–µ–≥–∏ —à–∞–≥–∞
}

export interface TrajectoryCandidate {
  id: string;
  label: string;
  originLayer: string; // –∫—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–∏–ª (–∞–≥–µ–Ω—Ç / –º–æ–¥—É–ª—å)
  steps: TrajectoryStep[];

  // –ü—Ä–æ–≥–Ω–æ–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞—é—Ç –Ω–∏–∂–µ–ª–µ–∂–∞—â–∏–µ —Å–ª–æ–∏ / –∞–≥–µ–Ω—Ç—ã
  predictedGain: number; // –æ–∂–∏–¥–∞–µ–º–∞—è "–≤—ã–≥–æ–¥–∞" 0..1
  predictedCost: number; // –æ–∂–∏–¥–∞–µ–º–∞—è "—Ü–µ–Ω–∞" 0..1
  predictedRisk: number; // –±–∞–∑–æ–≤—ã–π —Ä–∏—Å–∫ 0..1
  timeHorizonMs?: number;
  tags?: string[];
}

export interface DecisionContext {
  goalDescription: string;
  horizonMs: number;
  hardConstraints?: string[]; // "avoid:conflict-with-user", etc
  preferredRegions?: string[]; // –≥–¥–µ –ª—É—á—à–µ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å
  forbiddenRegions?: string[];
  timestamp: number;
}

export interface TrajectoryScores {
  resonanceScore: number; // 0..1 - –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è "–ª–æ–∂–∏—Ç—Å—è" –Ω–∞ —Å—Ä–µ–¥—É L23
  luckAlignment: number; // 0..1 - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ LuckVector
  environmentRisk: number; // 0..1 - –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å—Ä–µ–¥–∞ "–Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞" –¥–ª—è —ç—Ç–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
  structuralRisk: number; // 0..1 - —Ä–∏—Å–∫ –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —à–∞–≥–∞
  combinedScore: number; // –∏—Ç–æ–≥–æ–≤–∞—è —Å–≤—ë—Ä—Ç–∫–∞
}

export interface TrajectoryDecision {
  chosen: TrajectoryCandidate | null;
  ranked: Array<{ trajectory: TrajectoryCandidate; scores: TrajectoryScores }>;
  context: DecisionContext;
  reasonSummary: string;
}

export interface TrajectoryHarmonizerConfig {
  weightResonance: number; // –≤–µ—Å —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞ —Å–æ —Å—Ä–µ–¥–æ–π
  weightLuck: number; // –≤–µ—Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –≤–µ–∫—Ç–æ—Ä–æ–º L21
  weightRisk: number; // —à—Ç—Ä–∞—Ñ –∑–∞ —Ä–∏—Å–∫
  weightGain: number; // —Å–∫–æ–ª—å–∫–æ —É—á–∏—Ç—ã–≤–∞–µ–º predictedGain
}

export class TrajectoryHarmonizer {
  constructor(private config: TrajectoryHarmonizerConfig) {}

  decide(
    candidates: TrajectoryCandidate[],
    context: DecisionContext,
    env: InformationalFluidSnapshot,
    luck: LuckVector,
  ): TrajectoryDecision {
    const ranked = candidates
      .map((trajectory) => {
        const scores = this.scoreTrajectory(trajectory, context, env, luck);
        return { trajectory, scores };
      })
      .sort((a, b) => b.scores.combinedScore - a.scores.combinedScore);

    const chosen = ranked.length > 0 ? ranked[0].trajectory : null;

    return {
      chosen,
      ranked,
      context,
      reasonSummary: this.buildReasonSummary(ranked),
    };
  }

  // üîΩ –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ª–æ–≥–∏–∫–∞

  private scoreTrajectory(
    trajectory: TrajectoryCandidate,
    context: DecisionContext,
    env: InformationalFluidSnapshot,
    luck: LuckVector,
  ): TrajectoryScores {
    const resonanceScore = this.computeResonance(trajectory, env);
    const luckAlignment = this.computeLuckAlignment(trajectory, luck);
    const environmentRisk = this.computeEnvironmentRisk(trajectory, env);
    const structuralRisk = trajectory.predictedRisk;
    const contextPenalty = this.computeContextPenalty(trajectory, context);

    const gain = trajectory.predictedGain;
    const riskPenalty = ((environmentRisk + structuralRisk) / 2) * this.config.weightRisk;

    const combined =
      resonanceScore * this.config.weightResonance +
      luckAlignment * this.config.weightLuck +
      gain * this.config.weightGain -
      riskPenalty -
      contextPenalty;

    return {
      resonanceScore,
      luckAlignment,
      environmentRisk,
      structuralRisk,
      combinedScore: combined,
    };
  }

  private computeResonance(
    trajectory: TrajectoryCandidate,
    env: InformationalFluidSnapshot,
  ): number {
    let total = 0;
    let count = 0;

    for (const step of trajectory.steps) {
      const regions = step.involvedRegions ?? [];
      for (const regionId of regions) {
        const region: FluidRegionState | undefined = env.regions[regionId];
        if (!region) continue;
        const pattern = region.pattern;
        let score = 0.5;

        switch (pattern.phase) {
          case "fluid":
            score = 0.8;
            break;
          case "metastable":
            score = 0.6;
            break;
          case "frozen":
            score = 0.3;
            break;
          case "vapor":
            score = 0.2;
            break;
        }

        // –î–æ–±–∞–≤–ª—è–µ–º –≤–ª–∏—è–Ω–∏–µ coherence: —á–µ–º –±–æ–ª–µ–µ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–æ, —Ç–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ "–æ–ø–∏—Ä–∞—Ç—å—Å—è"
        score = score * 0.7 + pattern.coherence * 0.3;

        total += score;
        count += 1;
      }
    }

    if (count === 0) return 0.5; // –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–≥–∏–æ–Ω–æ–≤, —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–∏–º
    return total / count;
  }

  private computeLuckAlignment(trajectory: TrajectoryCandidate, luck: LuckVector): number {
    const trajectoryTags = new Set(trajectory.tags ?? []);
    let tagMatch = 0;

    for (const tag of luck.focusTags) {
      if (trajectoryTags.has(tag)) {
        tagMatch += 1;
      }
    }
    const tagScore = luck.focusTags.length > 0 ? tagMatch / luck.focusTags.length : 0.5;

    const riskDiff = Math.abs(trajectory.predictedRisk - luck.riskAppetite);
    const riskScore = 1 - riskDiff; // —á–µ–º –±–ª–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ

    const isChangeHeavy =
      (trajectory.timeHorizonMs ?? 0) > 0 && trajectory.predictedGain > 0.6 ? 1 : 0;
    const changeScore = 1 - Math.abs(isChangeHeavy - luck.changeDrive);

    return (tagScore + riskScore + changeScore) / 3;
  }

  private computeEnvironmentRisk(
    trajectory: TrajectoryCandidate,
    env: InformationalFluidSnapshot,
  ): number {
    let riskTotal = 0;
    let count = 0;

    for (const step of trajectory.steps) {
      const regions = step.involvedRegions ?? [];
      for (const regionId of regions) {
        const region = env.regions[regionId];
        if (!region) continue;

        const pattern = region.pattern;
        let localRisk = 0.5;

        switch (pattern.phase) {
          case "fluid":
            localRisk = 0.2;
            break;
          case "metastable":
            localRisk = 0.5;
            break;
          case "frozen":
            localRisk = 0.7;
            break;
          case "vapor":
            localRisk = 0.8;
            break;
        }

        // –ß–µ–º –Ω–∏–∂–µ coherence, —Ç–µ–º –≤—ã—à–µ —Ä–∏—Å–∫ (—Ö–∞–æ—Ç–∏—á–Ω–∞—è –≤–æ–¥–∞)
        localRisk = localRisk * 0.7 + (1 - pattern.coherence) * 0.3;

        riskTotal += localRisk;
        count += 1;
      }
    }

    if (count === 0) return 0.5;
    return riskTotal / count;
  }

  private computeContextPenalty(trajectory: TrajectoryCandidate, context: DecisionContext): number {
    const involvedRegions = new Set<string>();
    const trajectoryTags = new Set(trajectory.tags ?? []);

    for (const step of trajectory.steps) {
      for (const regionId of step.involvedRegions ?? []) {
        involvedRegions.add(regionId);
      }
      for (const tag of step.tags ?? []) {
        trajectoryTags.add(tag);
      }
    }

    let penalty = 0;

    if (context.forbiddenRegions?.some((region) => involvedRegions.has(region))) {
      penalty += 0.5;
    }

    if (context.preferredRegions && context.preferredRegions.length > 0) {
      let matches = 0;
      for (const preferred of context.preferredRegions) {
        if (involvedRegions.has(preferred)) {
          matches += 1;
        }
      }
      const coverage = matches / context.preferredRegions.length;
      penalty += (1 - coverage) * 0.3;
    }

    if (context.hardConstraints) {
      for (const constraint of context.hardConstraints) {
        if (constraint.startsWith("avoid:")) {
          const target = constraint.slice("avoid:".length);
          if (trajectoryTags.has(target)) {
            penalty += 0.4;
          }
        }
      }
    }

    return Math.min(1, penalty);
  }

  private buildReasonSummary(
    ranked: Array<{ trajectory: TrajectoryCandidate; scores: TrajectoryScores }>,
  ): string {
    if (ranked.length === 0) return "No trajectories provided.";

    const top = ranked[0];
    return [
      `Chosen trajectory: ${top.trajectory.label}`,
      `Resonance: ${(top.scores.resonanceScore * 100).toFixed(1)}%`,
      `Luck alignment: ${(top.scores.luckAlignment * 100).toFixed(1)}%`,
      `Environment risk: ${(top.scores.environmentRisk * 100).toFixed(1)}%`,
      `Combined score: ${top.scores.combinedScore.toFixed(3)}`,
    ].join(" | ");
  }
}
