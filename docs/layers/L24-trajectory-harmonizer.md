# L24 — Trajectory Harmonizer Layer (THL)

## Кратко

L24 отвечает за **выбор траектории движения организма** с учётом:

- текущего состояния среды (L23 — Informational Fluid),
- вектора воли/удачи (L21),
- нескольких альтернативных сценариев (TrajectoryCandidate).

Цель слоя — находить такие пути, которые:

- минимально конфликтуют со средой,
- максимально резонируют с текущим намерением системы,
- учитывают риск и турбулентность,
- и создают условия для устойчивого, "удачного" развития.

## Ключевые сущности

- **TrajectoryCandidate** — возможная траектория (план, стратегия, сценарий).
- **LuckVector (из L21)** — текущий "вектор воли" и риск-профиль.
- **InformationalFluidSnapshot (из L23)** — срез состояния информационной среды.
- **DecisionContext** — цель, ограничения, горизонт времени.
- **TrajectoryDecision** — результат выбора + ранжирование альтернатив.

## Принципы работы

1. Собираем список возможных траекторий от агентов / модулей.
2. Для каждой траектории:
   - оцениваем резонанс со средой (по фазам и coherence регионов L23),
   - оцениваем соответствие вектору воли/удачи (L21),
   - учитываем базовый риск и прогнозируемую "выгоду".
3. Рассчитываем интегральный `combinedScore` по конфигурируемым весам.
4. Возвращаем:
   - выбранную траекторию (`chosen`),
   - список всех альтернатив с их метриками (`ranked`),
   - краткое текстовое объяснение (`reasonSummary`).

### Метрики оценки

- `resonanceScore` — насколько шаги опираются на fluid/metastable регионы с высокой coherence (frozen/vapor штрафуются).
- `luckAlignment` — совпадение с фокус-тегами, риск-профилем и `changeDrive` из L21.
- `environmentRisk` — риск от фаз и инерции регионов (низкая coherence → хаос).
- `structuralRisk` — базовый риск кандидата.
- Итоговая свёртка:

```
combinedScore =
  resonanceScore * weightResonance +
  luckAlignment  * weightLuck +
  predictedGain  * weightGain -
  riskPenalty;

где riskPenalty = ((environmentRisk + structuralRisk) / 2) * weightRisk
```

Весовые коэффициенты настраиваются через `TrajectoryHarmonizerConfig` (консервативный/агрессивный режимы).

## Зачем это нужно

- Переводит удачу (L21) и состояние воды (L23) в **конкретный выбор "куда двигаться"**.
- Формирует у организма **поведение, похожее на удачу Домино**:
  не магию, а систематический выбор "мягких" и резонансных траекторий.
- Служит мостом к будущим слоям внутреннего голоса и совета (L25+),
  которые смогут опираться на L24 при формулировке рекомендаций и ответов.

## Что это даёт тебе сейчас, по-человечески

Если совсем по-простому, для Юры/Инвестора:

**До L24**
Система:

- знает, чего хочет (воля L21),
- знает, какая вокруг “погода” (вода L23),
- но ещё не умеет хорошо выбирать маршрут.

**После L24**
Система:

- видит несколько вариантов,
- чувствует, где вязко, где скользко, где легко,
- и выбирает путь, где и цель достигается, и меньше шансов влететь в стену.

Это и есть инженерная удача.
Не “повезло”, а “так настроена архитектура”.

## Пример

Минимальный сценарий с тремя траекториями и снимком среды: код в `docs/examples/L24-trajectory-demo.ts`, текстовое описание — `docs/examples/L24-trajectory-demo.md`.
